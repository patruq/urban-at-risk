{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:22:38.952221Z",
     "start_time": "2020-06-08T19:22:37.214294Z"
    }
   },
   "outputs": [],
   "source": [
    "# STANDARD LIBRARIES\n",
    "import pandas as pd\n",
    "from pandas._testing import assert_series_equal\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime as dt\n",
    "\n",
    "# GEOLOCATION\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import geocode\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from pyzipcode import ZipCodeDatabase\n",
    "\n",
    "\n",
    "# FEATURE ENGINEERING AND PREPROCESSING\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:57:13.920123Z",
     "start_time": "2020-06-08T00:57:13.612816Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# FROM CLEANING NOTEBOOK\n",
    "\n",
    "data = pd.read_csv(\"../data/clean-data/data-clean.csv\", low_memory=False)\n",
    "pw_df = pd.read_csv(\"../data/clean-data/pw_df-clean.csv\", low_memory=False)\n",
    "requests_df = pd.read_csv(\"../data/clean-data/requests_df-clean.csv\")\n",
    "fire_df = pd.read_csv(\"../data/clean-data/fire_df-clean.csv\")\n",
    "\n",
    "df_list = [\n",
    "    data,\n",
    "    pw_df,\n",
    "    requests_df,\n",
    "    fire_df\n",
    "]\n",
    "\n",
    "for df in df_list:\n",
    "    try:\n",
    "        df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:41:20.483086Z",
     "start_time": "2020-06-08T19:41:20.074760Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# READ ENG FILES:\n",
    "\n",
    "data = pd.read_csv(\"../data/clean-data/data-engineered.csv\")\n",
    "pw_df = pd.read_csv(\"../data/clean-data/pw_df-engineered.csv\")\n",
    "# fire_df = pd.read_csv(\"../data/clean-data/fire_df-engineered.csv\")\n",
    "# requests_df = pd.read_csv(\"../data/clean-data/requests_df-engineered.csv\")\n",
    "# main = pd.read_csv(\"../data/clean-data/main-engineered.csv\")\n",
    "\n",
    "df_list = [\n",
    "    data,\n",
    "    pw_df,\n",
    "#     requests_df,\n",
    "#     fire_df,\n",
    "#     main\n",
    "]\n",
    "\n",
    "\n",
    "for df in df_list:\n",
    "    try:\n",
    "        df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:29:44.616778Z",
     "start_time": "2020-06-08T19:29:44.613560Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97515, 45)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:22:39.887463Z",
     "start_time": "2020-06-08T19:22:39.783087Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv(\"../data/clean-data/data_1-eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:41:30.276888Z",
     "start_time": "2020-06-08T19:41:30.273213Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([col for col in pw_df.columns if \"description_\" in col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Function, Address & Geocodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Edit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:18:17.977972Z",
     "start_time": "2020-06-08T19:18:17.958575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_address_list(df):\n",
    "    \n",
    "    init_check = input(\"Do you have only one column to create full addresses? Enter 'yes' or 'no': \")\n",
    "    \n",
    "    if init_check.lower() == \"yes\":\n",
    "        status = True\n",
    "        while status:\n",
    "            try:\n",
    "                col = input(\"Enter a column to create address list: \")\n",
    "                address_list = list(df[col])\n",
    "                return address_list\n",
    "            except KeyError:\n",
    "                print(\"Please enter a valid column to create list\") \n",
    "                check_status = input(\"Would you like to continue? Enter 'yes' or 'no'\")\n",
    "                if check_status == \"no\":\n",
    "                    status = False\n",
    "                else:\n",
    "                    status = True\n",
    "    else:\n",
    "        address_list = []\n",
    "        return address_list\n",
    "\n",
    "    \n",
    "# SOME ADDRESSES NEED FURTHER CLEANING\n",
    "def clean_addresses(df, col=\"full_address\"):\n",
    "        \n",
    "    df[col] = df[col].replace({\n",
    "        \" st \": \" street\",\n",
    "        \" pk \": \" park\",\n",
    "        \" av \": \" avenue\",\n",
    "        \" ave \": \" avenue\",\n",
    "        \" ct \": \" court\",\n",
    "        \" dr \": \" drive\",\n",
    "        \" rd \": \" road\",\n",
    "        \" te \": \" terrace\",\n",
    "        \" cir \": \" circle\",\n",
    "        \" sq \": \" square\",\n",
    "        \" a \": \" \",\n",
    "        \" b \": \" \",\n",
    "        \" c \": \" \",\n",
    "        \" d \": \" \",\n",
    "        \" e \": \" \",\n",
    "        \" f \": \" \",\n",
    "        \" g \": \" \",\n",
    "        \" h \": \" \",\n",
    "        \" i \": \" \",\n",
    "        \" j \": \" \",\n",
    "        \" k \": \" \",\n",
    "        \" j \": \" \",\n",
    "        \" k \": \" \",\n",
    "        \" l \": \" \",\n",
    "        \" m \": \" \",\n",
    "        \" n \": \" \",\n",
    "        \" o \": \" \",\n",
    "        \" p \": \" \",\n",
    "        \" q \": \" \",\n",
    "        \" r \": \" \",\n",
    "        \" s \": \" \",\n",
    "        \" t \": \" \",\n",
    "        \" u \": \" \",\n",
    "        \" v \": \" \",\n",
    "        \" w \": \" \",\n",
    "        \" x \": \" \",\n",
    "        \" y \": \" \",\n",
    "        \" z \": \" \"\n",
    "    },\n",
    "    regex=True)\n",
    "    \n",
    "    return df    \n",
    "    \n",
    "\n",
    "\n",
    "def create_address_geolocator(df):\n",
    "    \n",
    "    address_list = create_address_list(df)\n",
    "    \n",
    "    if len(address_list) > 0:\n",
    "        for address in range(len(address_list)):\n",
    "            address_list[address] += \" boston, ma\"\n",
    "        df[\"full_address\"] = address_list\n",
    "    else:\n",
    "        \n",
    "        st_number = input(\"Enter street number column: \")\n",
    "        st_name = input(\"Enter street name column: \")\n",
    "        st_suffix = input(\"Enter street suffix column: \")\n",
    "        \n",
    "        print(st_number)\n",
    "        df[\"full_address\"] = df[st_number] + \" \" +\\\n",
    "                             df[st_name] + \" \" +\\\n",
    "                             df[st_suffix] + \" \" +\\\n",
    "                             \"boston, ma\"\n",
    "    df.drop_duplicates(subset=[\"full_address\"], inplace=True) #\n",
    "    df.reset_index(inplace=True) #\n",
    "    return df[\"full_address\"]\n",
    "\n",
    "\n",
    "\n",
    "def create_address_id(df):\n",
    "    \n",
    "    address_list = create_address_list(df)\n",
    "    \n",
    "    if len(address_list) > 0:\n",
    "#         for address in range(len(address_list)):\n",
    "#             address_list[address] += \" boston, ma\"\n",
    "        df[\"full_address\"] = address_list\n",
    "        df[\"full_address\"] = df[\"full_address\"].str.split()\n",
    "        df[\"full_address\"] = df[\"full_address\"].apply(lambda x: \" \".join(x[:3])) \n",
    "        df[\"full_address\"] = df[\"full_address\"].astype(str) + \" boston, ma\"\n",
    "        # https://stackoverflow.com/questions/45306988/column-of-lists-convert-list-to-string-as-a-new-column\n",
    "    else:\n",
    "        \n",
    "        st_number = input(\"Enter street number column: \")\n",
    "        st_name = input(\"Enter street name column: \")\n",
    "        st_suffix = input(\"Enter street suffix column: \")\n",
    "        \n",
    "        print(st_number)\n",
    "        df[\"full_address\"] = df[st_number] + \" \" +\\\n",
    "                             df[st_name] + \" \" +\\\n",
    "                             df[st_suffix] + \" \" +\\\n",
    "                             \"boston, ma\"\n",
    "    df.drop_duplicates(subset=[\"full_address\"], inplace=True) #\n",
    "    df.reset_index(inplace=True, drop=True) #\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def combine_lat_long(df):\n",
    "    try:\n",
    "        df[\"location\"] = list(zip(df[\"latitude\"], df[\"longitude\"]))\n",
    "    except KeyError:\n",
    "        df[\"location\"] = list(zip(df[\"lat\"], df[\"long\"]))\n",
    "\n",
    "        \n",
    "def create_geocodes(df):\n",
    "    \n",
    "    geolocator = Nominatim(user_agent=\"my-application\")\n",
    "    geocode_list = []\n",
    "    error_list = []\n",
    "    counter = 0\n",
    "    \n",
    "    addresses = create_address_geolocator(df)\n",
    "    addresses = pd.Series(addresses)\n",
    "    df.drop_duplicates(subset=[\"full_address\"], inplace=True) \n",
    "    \n",
    "    init_check = input(\"Do you have existing lat/long coords\"\\\n",
    "                       \"for this dataframe? Enter yes or no: \")\n",
    "    \n",
    "    if init_check == \"no\":\n",
    "        for address in addresses:\n",
    "#             print(address)\n",
    "            try:\n",
    "                latitude = geolocator.geocode(address).latitude\n",
    "                longitude= geolocator.geocode(address).longitude\n",
    "                geocode_list.append((latitude, longitude))\n",
    "                counter += 1\n",
    "            except AttributeError:\n",
    "                error_list.append(address)\n",
    "                print(f\"Could not create coordindates for {address}\")\n",
    "                pass\n",
    "            except GeocoderTimedOut:\n",
    "                if attempt <= max_attempts:\n",
    "                    get_geocodes(address, attempt=attempt+1)\n",
    "                raise\n",
    "            if counter % 500 == 0:\n",
    "                print(f\"Completed Address Count: {counter}\")\n",
    "                \n",
    "        df[\"location\"] = pd.Series(geocode_list)\n",
    "        \n",
    "    else:\n",
    "        df[\"location\"] = combine_lat_long(df)\n",
    "\n",
    "\n",
    "    return df, error_list\n",
    "\n",
    "\n",
    "                # https://gis.stackexchange.com/questions/173569/avoid-time-out-error-nominatim-geopy-open-street-maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T19:18:14.101564Z",
     "start_time": "2020-06-08T19:18:14.067828Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_address_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7489a1c2445f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_address_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# pw_df = create_address_id(pw_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# requests_df = create_address_id(requests_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_address_id' is not defined"
     ]
    }
   ],
   "source": [
    "data = create_address_id(data)\n",
    "# pw_df = create_address_id(pw_df)\n",
    "# requests_df = create_address_id(requests_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T00:06:44.567934Z",
     "start_time": "2020-06-04T00:06:39.360Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = clean_addresses(data, \"full_address\")\n",
    "# pw_df = clean_addresses(pw_df, \"full_address\")\n",
    "# requests_df = clean_addresses(requests_df, \"full_address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T00:06:44.568549Z",
     "start_time": "2020-06-04T00:06:39.361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data = clean_addresses(data, \"st_name_suf\")\n",
    "# pw_df = clean_addresses(pw_df, \"st_name_suf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Protected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T00:06:44.569182Z",
     "start_time": "2020-06-04T00:06:39.363Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# COMPLETED:\n",
    "    # IN ORDER TO EXPEDITE THIS, WILL DIVIDE THE DF UP INTO 10 CHUNKS\n",
    "    # data_1\n",
    "    \n",
    "# data_1, data_2, data_3, data_4,data_5,\\\n",
    "# data_6, data_7, data_8, data_9, data_10,\\\n",
    "# data_11, data_12, data_13, data_14, data_15 = np.array_split(data, 15)\n",
    "\n",
    "# data_2, error_list_2 = create_geocodes(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T00:06:44.569705Z",
     "start_time": "2020-06-04T00:06:39.365Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# error_list_1 = error_list\n",
    "# print(len(error_list_1))\n",
    "# error_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T00:06:44.570253Z",
     "start_time": "2020-06-04T00:06:39.366Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(data_1.shape)\n",
    "# data_1.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:57:24.679599Z",
     "start_time": "2020-06-08T00:57:24.676884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_encode_list = [\n",
    "    \"lu\"\n",
    "]\n",
    "\n",
    "pw_df_encode_list = [\n",
    "    \"description\"\n",
    "]\n",
    "\n",
    "requests_encode_list = [\n",
    "#     \"reason\",\n",
    "    \"source\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:41:58.354642Z",
     "start_time": "2020-06-08T00:41:58.348707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# BUG WITH THIS FUNCTION TAKING IN MORE THAN ONE COLUMN FROM LIST\n",
    "\n",
    "def create_encoder(df, col_list):\n",
    "    \n",
    "#     init_check = input(\"Would you like to OneHotEncode this Dataset?\"\\\n",
    "#                         \" Enter 'yes' or 'no': \")\n",
    "    df_encoder_list = []\n",
    "    \n",
    "#     if init_check == \"yes\":\n",
    "    for col in col_list:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "        df[col + \"_category\"] = df[col].cat.codes\n",
    "        print(f\"Created category column for column: {col}\")\n",
    "\n",
    "        df_encoder_list.append(col + \"_category\") \n",
    "        print(df_encoder_list)\n",
    "\n",
    "        encoder = OneHotEncoder(\n",
    "#             drop=\"first\",\n",
    "            handle_unknown=\"error\"\n",
    "        )\n",
    "            \n",
    "        enc_df = pd.DataFrame(encoder.fit_transform(df[df_encoder_list]).toarray())\n",
    "        enc_df.columns = encoder.get_feature_names(df_encoder_list)\n",
    "            \n",
    "        df = pd.concat([df, enc_df], axis=1)\n",
    "        # https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n",
    "            \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:57:18.638987Z",
     "start_time": "2020-06-08T00:57:18.597561Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created category column for column: lu\n",
      "['lu_category']\n"
     ]
    }
   ],
   "source": [
    "data = create_encoder(data, data_encode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:57:19.010418Z",
     "start_time": "2020-06-08T00:57:18.990374Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created category column for column: description\n",
      "['description_category']\n"
     ]
    }
   ],
   "source": [
    "pw_df = create_encoder(pw_df, pw_df_encode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:57:26.827625Z",
     "start_time": "2020-06-08T00:57:26.764192Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created category column for column: source\n",
      "['source_category']\n"
     ]
    }
   ],
   "source": [
    "requests_df = create_encoder(requests_df, requests_encode_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:57:28.633229Z",
     "start_time": "2020-06-08T00:57:28.604127Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data[\"own_occ\"] = data[\"own_occ\"].map({\"n\": 0, \"y\":1})\n",
    "\n",
    "pw_df[\"status\"] = pw_df[\"status\"].map({\"closed\": 0, \"open\": 1})\n",
    "\n",
    "requests_df[\"case_status\"] = requests_df[\"case_status\"].map({\"closed\": 0, \"open\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:57:52.218931Z",
     "start_time": "2020-06-08T00:57:30.380378Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data[\"zipcode\"] = data[\"zipcode\"].astype(str)\n",
    "data[\"zipcode\"] = data[\"zipcode\"].apply(lambda x: \"0\" + x[:4])  \n",
    "\n",
    "#===================================================\n",
    "data[\"num_street\"] = data[[\"st_num\", \"st_name\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "data[\"zip_street\"] = data[[\"st_name\", \"zipcode\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "data[\"zip_num_street\"] = data[[\"num_street\", \"zipcode\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "\n",
    "#===================================================\n",
    "data[\"sum_land_value_street\"] = data.groupby(\"zip_street\")[\"av_land\"].transform('sum')\n",
    "data[\"sum_bldg_value_street\"] = data.groupby(\"zip_street\")[\"av_bldg\"].transform('sum')\n",
    "data[\"sum_total_value_street\"] = data.groupby(\"zip_street\")[\"av_total\"].transform('sum')\n",
    "data[\"sum_gross_tax_street\"] = data.groupby(\"zip_street\")[\"gross_tax\"].transform('sum')\n",
    "\n",
    "data[\"avg_land_value_street\"] = data.groupby(\"zip_street\")[\"av_land\"].transform('mean')\n",
    "data[\"avg_bldg_value_street\"] = data.groupby(\"zip_street\")[\"av_bldg\"].transform('mean')\n",
    "data[\"avg_total_value_street\"] = data.groupby(\"zip_street\")[\"av_total\"].transform('mean')\n",
    "data[\"avg_gross_tax_street\"] = data.groupby(\"zip_street\")[\"gross_tax\"].transform('mean')\n",
    "\n",
    "data[\"sum_land_value_zip\"] = data.groupby(\"zipcode\")[\"av_land\"].transform('sum')\n",
    "data[\"sum_bldg_value_zip\"] = data.groupby(\"zipcode\")[\"av_bldg\"].transform('sum')\n",
    "data[\"sum_total_value_zip\"] = data.groupby(\"zipcode\")[\"av_total\"].transform('sum')\n",
    "data[\"sum_gross_tax_zip\"] = data.groupby(\"zipcode\")[\"gross_tax\"].transform('sum')\n",
    "\n",
    "data[\"avg_land_value_zip\"] = data.groupby(\"zipcode\")[\"av_land\"].transform('mean')\n",
    "data[\"avg_bldg_value_zip\"] = data.groupby(\"zipcode\")[\"av_bldg\"].transform('mean')\n",
    "data[\"avg_total_value_zip\"] = data.groupby(\"zipcode\")[\"av_total\"].transform('mean')\n",
    "data[\"avg_gross_tax_zip\"] = data.groupby(\"zipcode\")[\"gross_tax\"].transform('mean')\n",
    "#===================================================\n",
    "lu_cols = [col for col in data.columns if \"lu_category_\" in col]\n",
    "\n",
    "for col in lu_cols:\n",
    "    # COMMENT/UNCOMMENT TO INCLUDE PROPERTY AND STREET LEVEL TOTALS\n",
    "#     data[f\"sum_{col}_prop\"] = data.groupby(\"zip_num_street\")[col].transform('sum')\n",
    "#     data[f\"sum_{col}_street\"] = data.groupby(\"zip_street\")[col].transform('sum')\n",
    "    data[f\"sum_{col}_zip\"] = data.groupby(\"zipcode\")[col].transform('sum')\n",
    "    \n",
    "    # UNCOMMENT TO INCLUDE AVERAGES\n",
    "#     data[f\"avg_{col}_street\"] = data.groupby(\"zip_street\")[col].transform('mean')\n",
    "#     data[f\"avg_{col}_zip\"] = data.groupby(\"zip_num_street\")[col].transform('mean')\n",
    "    data.drop(columns=[col], inplace=True)\n",
    "\n",
    "#===================================================\n",
    "    # COMMENT/UNCOMMENT TO INCLUDE PROPERTY AND STREET LEVEL TOTALS\n",
    "data[\"owner_occ_prop\"] = data.groupby(\"zip_street\")[\"own_occ\"].transform('sum')\n",
    "data[\"owner_occ_street\"] = data.groupby(\"zip_street\")[\"own_occ\"].transform('sum')\n",
    "data[\"sum_owner_occ_zipcode\"] = data.groupby(\"zipcode\")[\"own_occ\"].transform('sum')\n",
    "\n",
    "#===================================================\n",
    "data.rename(columns={\n",
    "    \"av_land\": \"land_value_prop\",\n",
    "    \"av_bldg\": \"build_value_prop\",\n",
    "    \"av_total\": \"total_value_prop\",\n",
    "    \"gross_tax\": \"gross_tax_prop\"\n",
    "})\n",
    "\n",
    "#===================================================\n",
    "data.drop(columns=[\"st_num\",\n",
    "#                    \"gis_id\",\n",
    "#                    \"st_name\",\n",
    "#                    \"st_name_suf\",\n",
    "                   \"lu\",\n",
    "#                    \"lu_category\",\n",
    "                   \"own_occ\"\n",
    "#                    \"av_land\",\n",
    "#                    \"av_bldg\",\n",
    "#                    \"av_total\",\n",
    "#                    \"gross_tax\"\n",
    "                  ], inplace=True)\n",
    "\n",
    "#===================================================\n",
    "data = data.drop_duplicates(subset=\"zip_num_street\")\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_cols = list(data.columns)\n",
    "\n",
    "filename = \"../assets/variables/data_cols\"\n",
    "outfile = open(filename, \"wb\")\n",
    "pickle.dump(data_cols, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T20:38:59.577150Z",
     "start_time": "2020-06-05T20:38:59.574870Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# lu_cat_dict = {\n",
    "#     0: \"a\",\n",
    "#     1: \"ah\",\n",
    "#     2: \"c\",\n",
    "#     3: \"cc\", \n",
    "#     4: \"cd\", \n",
    "#     5: \"cl\",\n",
    "#     6: \"cm\",\n",
    "#     7: \"e\",\n",
    "#     8: \"ea\",\n",
    "#     9: \"i\",\n",
    "#     10: \"r1\",\n",
    "#     11: \"r2\",\n",
    "#     12: \"r3\",\n",
    "#     13: \"r4\",\n",
    "#     14: \"rc\",\n",
    "#     15: \"rl\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### pw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:58:06.285970Z",
     "start_time": "2020-06-08T00:57:59.316510Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pw_df[\"pw_num_street\"] = pw_df[[\"st_num\", \"st_name\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "pw_df[\"pw_zip_street\"] = pw_df[[\"st_name\", \"zipcode\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "pw_df[\"pw_zip_num_street\"] = pw_df[[\"pw_num_street\", \"zipcode\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "#========================================\n",
    "\n",
    "# CREATE COLUMNS OF TOTAL VIOLATIONS AND AVG NUMBER OF VIOLATIONS\n",
    "pw_df[\"pw_viol_count_prop\"] = pw_df.groupby(\"pw_zip_num_street\")[\"pw_violation\"].transform('sum')\n",
    "pw_df[\"sum_pw_viol_count_street\"] = pw_df.groupby(\"pw_zip_street\")[\"pw_violation\"].transform('sum')\n",
    "pw_df[\"sum_pw_viol_count_zip\"] = pw_df.groupby(\"zipcode\")[\"pw_violation\"].transform(\"sum\")\n",
    "\n",
    "pw_df[\"avg_pw_violations_street\"] = pw_df.groupby(\"pw_zip_street\")[\"pw_violation\"].transform(\"mean\")\n",
    "pw_df[\"avg_pw_violations_zip\"] = pw_df.groupby(\"zipcode\")[\"pw_violation\"].transform(\"mean\")\n",
    "\n",
    "#========================================\n",
    "# CREATE COLUMNS OF $ FINE AMOUNTS AND AVGs\n",
    "pw_df[\"sum_pw_fine_value_prop\"] = pw_df.groupby(\"pw_zip_num_street\")[\"value\"].transform('sum')\n",
    "pw_df[\"sum_pw_fine_value_street\"] = pw_df.groupby(\"pw_zip_street\")[\"value\"].transform('sum')\n",
    "pw_df[\"sum_pw_fine_value_zip\"] = pw_df.groupby(\"zipcode\")[\"value\"].transform('sum')\n",
    "\n",
    "pw_df[\"avg_pw_fine_value_street\"] = pw_df.groupby(\"pw_zip_street\")[\"value\"].transform('mean')\n",
    "pw_df[\"avg_pw_fine_value_zip\"] = pw_df.groupby(\"zipcode\")[\"value\"].transform('mean')\n",
    "\n",
    "#========================================\n",
    "\n",
    "# SUMS OF OPEN PW VIOLATIONS BY STREET AND ZIP\n",
    "pw_df[\"sum_pw_open_status_prop\"] = pw_df.groupby(\"pw_zip_num_street\")[\"status\"].transform('sum')\n",
    "pw_df[\"sum_pw_open_status_street\"] = pw_df.groupby(\"pw_zip_street\")[\"status\"].transform('sum')\n",
    "pw_df[\"sum_pw_open_status_zip\"] = pw_df.groupby(\"zipcode\")[\"status\"].transform('sum')\n",
    "\n",
    "#========================================\n",
    "pw_df.rename(columns={\"value\": \"pw_viol_value_prop\"}, inplace=True)\n",
    "\n",
    "description_cols = [col for col in pw_df.columns if \"description_category_\" in col]\n",
    "\n",
    "for col in description_cols:\n",
    "    pw_df[f\"{col}_total\"] = pw_df.groupby(\"pw_zip_num_street\")[col].transform('sum')\n",
    "    pw_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "pw_df.drop(columns=[\n",
    "    \"st_num\",\n",
    "    \"st_name\",\n",
    "    \"status\",\n",
    "    \"description\",\n",
    "    \"description_category\",\n",
    "    \"pw_violation\"\n",
    "#     \"value\"\n",
    "],\n",
    "          inplace=True)\n",
    "\n",
    "pw_df.zipcode.str.replace(\"2120\", \"02120\")\n",
    "pw_df = pw_df[pw_df[\"zipcode\"] != \" \"]\n",
    "pw_df = pw_df.drop_duplicates(subset=\"pw_zip_num_street\")\n",
    "pw_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "pw_cols = list(pw_df.columns)\n",
    "\n",
    "filename = \"../assets/variables/pw_cols\"\n",
    "outfile = open(filename, \"wb\")\n",
    "pickle.dump(pw_cols, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### fire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:58:14.175268Z",
     "start_time": "2020-06-08T00:58:07.829090Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fire_df[\"zipcode\"] = fire_df[\"zipcode\"].astype(str)\n",
    "fire_df[\"zipcode\"] = fire_df[\"zipcode\"].apply(lambda x: \"0\" + x)  \n",
    "\n",
    "fire_df[\"fire_num_street\"] = fire_df[[\"st_num\", \"st_name\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "fire_df[\"fire_zip_street\"] = fire_df[[\"st_name\", \"zipcode\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "fire_df[\"fire_zip_num_street\"] = fire_df[[\"fire_num_street\", \"zipcode\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "\n",
    "#============================================================\n",
    "fire_df[\"fire_prop_loss_prop\"] = fire_df.groupby(\"fire_zip_num_street\")[\"estimated property loss\"].transform(\"sum\")\n",
    "fire_df[\"sum_fire_prop_loss_street\"] = fire_df.groupby(\"fire_zip_street\")[\"estimated property loss\"].transform('sum')\n",
    "fire_df[\"sum_fire_prop_loss_zip\"] = fire_df.groupby(\"zipcode\")[\"estimated property loss\"].transform('sum')\n",
    "\n",
    "fire_df[\"avg_fire_prop_loss_street\"] = fire_df.groupby(\"fire_zip_num_street\")[\"estimated property loss\"].transform(\"mean\")\n",
    "fire_df[\"avg_fire_prop_loss_street\"] = fire_df.groupby(\"fire_zip_street\")[\"estimated property loss\"].transform('mean')\n",
    "fire_df[\"avg_fire_prop_loss_zip\"] = fire_df.groupby(\"zipcode\")[\"estimated property loss\"].transform('mean')\n",
    "\n",
    "\n",
    "#============================================================\n",
    "fire_df[\"sum_fire_content_loss_prop\"] = fire_df.groupby(\"fire_zip_num_street\")[\"estimated content loss\"].transform(\"sum\")\n",
    "fire_df[\"sum_fire_content_loss_street\"] = fire_df.groupby(\"fire_zip_street\")[\"estimated content loss\"].transform('sum')\n",
    "fire_df[\"sum_fire_content_loss_zip\"] = fire_df.groupby(\"zipcode\")[\"estimated content loss\"].transform('sum')\n",
    "\n",
    "fire_df[\"avg_fire_content_loss_prop\"] = fire_df.groupby(\"fire_zip_num_street\")[\"estimated content loss\"].transform(\"mean\")\n",
    "fire_df[\"avg_fire_content_loss_street\"] = fire_df.groupby(\"fire_zip_street\")[\"estimated content loss\"].transform('mean')\n",
    "fire_df[\"avg_fire_content_loss_zip\"] = fire_df.groupby(\"zipcode\")[\"estimated content loss\"].transform('mean')\n",
    "\n",
    "#============================================================\n",
    "fire_df[\"total_fire_loss_street\"] = fire_df[\"sum_fire_content_loss_street\"] + fire_df[\"sum_fire_prop_loss_street\"]\n",
    "fire_df[\"total_fire_loss_zip\"] = fire_df[\"sum_fire_content_loss_zip\"] + fire_df[\"sum_fire_prop_loss_zip\"]\n",
    "\n",
    "#============================================================\n",
    "fire_df[\"sum_fire_incidents_prop\"] = fire_df.groupby(\"fire_zip_num_street\")[\"had_incident\"].transform(\"sum\")\n",
    "fire_df[\"sum_fire_incidents_street\"] = fire_df.groupby(\"fire_zip_street\")[\"had_incident\"].transform(\"sum\")\n",
    "fire_df[\"sum_fire_incidents_zip\"] = fire_df.groupby(\"zipcode\")[\"had_incident\"].transform(\"sum\")\n",
    "\n",
    "#============================================================\n",
    "fire_df = fire_df.drop_duplicates(subset=\"fire_zip_num_street\")\n",
    "fire_df = fire_df.drop(columns=[\"st_name\", \n",
    "                                \"st_num\",\n",
    "                                \"had_incident\"])\n",
    "#                                 \"estimated property loss\",\n",
    "#                                 \"estimated content loss\"])\n",
    "fire_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#============================================================\n",
    "fire_cols = list(fire_df.columns)\n",
    "\n",
    "filename = \"../assets/variables/fire_cols\"\n",
    "outfile = open(filename, \"wb\")\n",
    "pickle.dump(fire_cols, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### requests_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:58:42.796837Z",
     "start_time": "2020-06-08T00:58:16.685498Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "requests_df[\"zipcode\"] = requests_df[\"zipcode\"].astype(str)\n",
    "requests_df[\"zipcode\"] = requests_df[\"zipcode\"].apply(lambda x: \"0\" + x[:4])  \n",
    "#===============================================\n",
    "\n",
    "requests_df[\"req_num_street\"] = requests_df[[\"st_num\", \"st_name\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "requests_df[\"req_zip_street\"] = requests_df[[\"st_name\", \"zipcode\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "requests_df[\"req_zip_num_street\"] = requests_df[[\"req_num_street\", \"zipcode\"]].astype(str).apply(lambda x: ' '.join(pd.unique(' '.join(x).split())),axis=1)\n",
    "#===============================================\n",
    "\n",
    "# CREATE COLUMN OF TOTAL REQUESTS MADE TO THE CITY\n",
    "requests_df[\"requests_total_prop\"] = requests_df.groupby(\"req_zip_num_street\")[\"had_request\"].transform('sum')\n",
    "requests_df[\"requests_total_street\"] = requests_df.groupby(\"req_zip_street\")[\"had_request\"].transform('sum')\n",
    "requests_df[\"requests_total_zip\"] = requests_df.groupby(\"zipcode\")[\"had_request\"].transform('sum')\n",
    "\n",
    "requests_df[\"req_open_status_prop\"] = requests_df.groupby(\"req_zip_num_street\")[\"case_status\"].transform('sum')\n",
    "requests_df[\"req_open_status_street\"] = requests_df.groupby(\"req_zip_street\")[\"case_status\"].transform('sum')\n",
    "requests_df[\"req_open_status_zip\"] = requests_df.groupby(\"zipcode\")[\"case_status\"].transform('sum')\n",
    "\n",
    "reason_col = [col for col in requests_df.columns if \"reason_category_\" in col]\n",
    "source_col = [col for col in requests_df.columns if \"source_category_\" in col]\n",
    "\n",
    "#===============================================\n",
    "# for col in reason_col:\n",
    "#     requests_df[f\"req_{col}_total_prop\"] = requests_df.groupby(\"req_zip_num_street\")[col].transform('sum')\n",
    "# for col in reason_col:\n",
    "#     requests_df[f\"req_{col}_total_street\"] = requests_df.groupby(\"req_zip_street\")[col].transform('sum')\n",
    "for col in reason_col:\n",
    "#     requests_df[f\"req_{col}_total_zip\"] = requests_df.groupby(\"zipcode\")[col].transform('sum')\n",
    "    requests_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# for col in source_col:\n",
    "#     requests_df[f\"req_{col}_total_prop\"] = requests_df.groupby(\"req_zip_num_street\")[col].transform('sum')\n",
    "# for col in source_col:\n",
    "#     requests_df[f\"req_{col}_total_street\"] = requests_df.groupby(\"req_zip_street\")[col].transform('sum')\n",
    "for col in source_col:\n",
    "#     requests_df[f\"req_{col}_total_zip\"] = requests_df.groupby(\"zipcode\")[col].transform('sum')\n",
    "    requests_df.drop(columns=[col], inplace=True)\n",
    "#===============================================\n",
    "    \n",
    "requests_df.drop_duplicates(subset=\"req_zip_num_street\", inplace=True)\n",
    "requests_df.drop(columns=[\n",
    "    \"st_name\",\n",
    "#     \"open_dt\",\n",
    "    \"case_status\",\n",
    "    \"reason\",\n",
    "    \"reason_category\",\n",
    "    \"source\",\n",
    "    \"source_category\",\n",
    "    \"had_request\",\n",
    "],inplace=True)\n",
    "requests_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#===============================================\n",
    "requests_cols = list(requests_df.columns)\n",
    "filename = \"../assets/variables/requests_cols\"\n",
    "outfile = open(filename, \"wb\")\n",
    "pickle.dump(requests_cols, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Check Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:37:03.279379Z",
     "start_time": "2020-06-05T21:37:03.238912Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97515, 39)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_name</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lu_category</th>\n",
       "      <th>num_street</th>\n",
       "      <th>zip_street</th>\n",
       "      <th>zip_num_street</th>\n",
       "      <th>sum_land_value_street</th>\n",
       "      <th>sum_bldg_value_street</th>\n",
       "      <th>sum_total_value_street</th>\n",
       "      <th>sum_gross_tax_street</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_lu_category_7_zip</th>\n",
       "      <th>sum_lu_category_8_zip</th>\n",
       "      <th>sum_lu_category_9_zip</th>\n",
       "      <th>sum_lu_category_10_zip</th>\n",
       "      <th>sum_lu_category_11_zip</th>\n",
       "      <th>sum_lu_category_12_zip</th>\n",
       "      <th>sum_lu_category_13_zip</th>\n",
       "      <th>sum_lu_category_14_zip</th>\n",
       "      <th>sum_lu_category_15_zip</th>\n",
       "      <th>sumowner_occ_zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beacon</td>\n",
       "      <td>02108</td>\n",
       "      <td>4</td>\n",
       "      <td>87 beacon</td>\n",
       "      <td>beacon 02108</td>\n",
       "      <td>87 beacon 02108</td>\n",
       "      <td>188299425</td>\n",
       "      <td>1264932993</td>\n",
       "      <td>1453232418</td>\n",
       "      <td>2540703954</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beacon</td>\n",
       "      <td>02108</td>\n",
       "      <td>6</td>\n",
       "      <td>88 beacon</td>\n",
       "      <td>beacon 02108</td>\n",
       "      <td>88 beacon 02108</td>\n",
       "      <td>188299425</td>\n",
       "      <td>1264932993</td>\n",
       "      <td>1453232418</td>\n",
       "      <td>2540703954</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beacon</td>\n",
       "      <td>02108</td>\n",
       "      <td>0</td>\n",
       "      <td>89 beacon</td>\n",
       "      <td>beacon 02108</td>\n",
       "      <td>89 beacon 02108</td>\n",
       "      <td>188299425</td>\n",
       "      <td>1264932993</td>\n",
       "      <td>1453232418</td>\n",
       "      <td>2540703954</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beacon</td>\n",
       "      <td>02108</td>\n",
       "      <td>6</td>\n",
       "      <td>90 beacon</td>\n",
       "      <td>beacon 02108</td>\n",
       "      <td>90 beacon 02108</td>\n",
       "      <td>188299425</td>\n",
       "      <td>1264932993</td>\n",
       "      <td>1453232418</td>\n",
       "      <td>2540703954</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beacon</td>\n",
       "      <td>02108</td>\n",
       "      <td>6</td>\n",
       "      <td>91 beacon</td>\n",
       "      <td>beacon 02108</td>\n",
       "      <td>91 beacon 02108</td>\n",
       "      <td>188299425</td>\n",
       "      <td>1264932993</td>\n",
       "      <td>1453232418</td>\n",
       "      <td>2540703954</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  st_name zipcode  lu_category num_street    zip_street   zip_num_street  \\\n",
       "0  beacon   02108            4  87 beacon  beacon 02108  87 beacon 02108   \n",
       "1  beacon   02108            6  88 beacon  beacon 02108  88 beacon 02108   \n",
       "2  beacon   02108            0  89 beacon  beacon 02108  89 beacon 02108   \n",
       "3  beacon   02108            6  90 beacon  beacon 02108  90 beacon 02108   \n",
       "4  beacon   02108            6  91 beacon  beacon 02108  91 beacon 02108   \n",
       "\n",
       "   sum_land_value_street  sum_bldg_value_street  sum_total_value_street  \\\n",
       "0              188299425             1264932993              1453232418   \n",
       "1              188299425             1264932993              1453232418   \n",
       "2              188299425             1264932993              1453232418   \n",
       "3              188299425             1264932993              1453232418   \n",
       "4              188299425             1264932993              1453232418   \n",
       "\n",
       "   sum_gross_tax_street  ...  sum_lu_category_7_zip  sum_lu_category_8_zip  \\\n",
       "0            2540703954  ...                   76.0                    0.0   \n",
       "1            2540703954  ...                   76.0                    0.0   \n",
       "2            2540703954  ...                   76.0                    0.0   \n",
       "3            2540703954  ...                   76.0                    0.0   \n",
       "4            2540703954  ...                   76.0                    0.0   \n",
       "\n",
       "   sum_lu_category_9_zip  sum_lu_category_10_zip  sum_lu_category_11_zip  \\\n",
       "0                    0.0                   220.0                    23.0   \n",
       "1                    0.0                   220.0                    23.0   \n",
       "2                    0.0                   220.0                    23.0   \n",
       "3                    0.0                   220.0                    23.0   \n",
       "4                    0.0                   220.0                    23.0   \n",
       "\n",
       "   sum_lu_category_12_zip  sum_lu_category_13_zip  sum_lu_category_14_zip  \\\n",
       "0                    13.0                    30.0                    41.0   \n",
       "1                    13.0                    30.0                    41.0   \n",
       "2                    13.0                    30.0                    41.0   \n",
       "3                    13.0                    30.0                    41.0   \n",
       "4                    13.0                    30.0                    41.0   \n",
       "\n",
       "   sum_lu_category_15_zip  sumowner_occ_zipcode  \n",
       "0                     4.0                   651  \n",
       "1                     4.0                   651  \n",
       "2                     4.0                   651  \n",
       "3                     4.0                   651  \n",
       "4                     4.0                   651  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.isna().sum().sum())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### pw violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:37:05.176469Z",
     "start_time": "2020-06-05T21:37:05.151228Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17629, 55)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>pw_viol_value_prop</th>\n",
       "      <th>pw_num_street</th>\n",
       "      <th>pw_zip_street</th>\n",
       "      <th>pw_zip_num_street</th>\n",
       "      <th>sum_pw_viol_count_street</th>\n",
       "      <th>sum_pw_viol_count_zip</th>\n",
       "      <th>avg_pw_violations_street</th>\n",
       "      <th>avg_pw_violations_zip</th>\n",
       "      <th>sum_pw_fine_value_street</th>\n",
       "      <th>...</th>\n",
       "      <th>description_category_30_total</th>\n",
       "      <th>description_category_31_total</th>\n",
       "      <th>description_category_32_total</th>\n",
       "      <th>description_category_33_total</th>\n",
       "      <th>description_category_34_total</th>\n",
       "      <th>description_category_35_total</th>\n",
       "      <th>description_category_36_total</th>\n",
       "      <th>description_category_37_total</th>\n",
       "      <th>description_category_38_total</th>\n",
       "      <th>description_category_39_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02118</td>\n",
       "      <td>25</td>\n",
       "      <td>21 concord</td>\n",
       "      <td>concord 02118</td>\n",
       "      <td>21 concord 02118</td>\n",
       "      <td>182</td>\n",
       "      <td>3184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02115</td>\n",
       "      <td>25</td>\n",
       "      <td>196 saint botolph</td>\n",
       "      <td>saint botolph 02115</td>\n",
       "      <td>196 saint botolph 02115</td>\n",
       "      <td>134</td>\n",
       "      <td>2323</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02108</td>\n",
       "      <td>25</td>\n",
       "      <td>68 pinckney</td>\n",
       "      <td>pinckney 02108</td>\n",
       "      <td>68 pinckney 02108</td>\n",
       "      <td>4</td>\n",
       "      <td>369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02114</td>\n",
       "      <td>250</td>\n",
       "      <td>165 friend</td>\n",
       "      <td>friend 02114</td>\n",
       "      <td>165 friend 02114</td>\n",
       "      <td>8</td>\n",
       "      <td>2166</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02113</td>\n",
       "      <td>25</td>\n",
       "      <td>263 north</td>\n",
       "      <td>north 02113</td>\n",
       "      <td>263 north 02113</td>\n",
       "      <td>231</td>\n",
       "      <td>2882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  zipcode  pw_viol_value_prop      pw_num_street        pw_zip_street  \\\n",
       "0   02118                  25         21 concord        concord 02118   \n",
       "1   02115                  25  196 saint botolph  saint botolph 02115   \n",
       "2   02108                  25        68 pinckney       pinckney 02108   \n",
       "3   02114                 250         165 friend         friend 02114   \n",
       "4   02113                  25          263 north          north 02113   \n",
       "\n",
       "         pw_zip_num_street  sum_pw_viol_count_street  sum_pw_viol_count_zip  \\\n",
       "0         21 concord 02118                       182                   3184   \n",
       "1  196 saint botolph 02115                       134                   2323   \n",
       "2        68 pinckney 02108                         4                    369   \n",
       "3         165 friend 02114                         8                   2166   \n",
       "4          263 north 02113                       231                   2882   \n",
       "\n",
       "   avg_pw_violations_street  avg_pw_violations_zip  sum_pw_fine_value_street  \\\n",
       "0                         1                      1                      6975   \n",
       "1                         1                      1                      4290   \n",
       "2                         1                      1                       100   \n",
       "3                         1                      1                      1025   \n",
       "4                         1                      1                     10600   \n",
       "\n",
       "   ...  description_category_30_total  description_category_31_total  \\\n",
       "0  ...                            0.0                            0.0   \n",
       "1  ...                            0.0                            0.0   \n",
       "2  ...                            0.0                            0.0   \n",
       "3  ...                            0.0                            0.0   \n",
       "4  ...                            0.0                            0.0   \n",
       "\n",
       "   description_category_32_total  description_category_33_total  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   description_category_34_total  description_category_35_total  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   description_category_36_total  description_category_37_total  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   description_category_38_total  description_category_39_total  \n",
       "0                            0.0                            0.0  \n",
       "1                            0.0                            0.0  \n",
       "2                            0.0                            0.0  \n",
       "3                            0.0                            0.0  \n",
       "4                            0.0                            0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pw_df.shape)\n",
    "print(pw_df.isna().sum().sum())\n",
    "pw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### fire incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:37:07.377437Z",
     "start_time": "2020-06-05T21:37:07.358505Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21051, 14)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>estimated property loss</th>\n",
       "      <th>estimated content loss</th>\n",
       "      <th>fire_num_street</th>\n",
       "      <th>fire_zip_street</th>\n",
       "      <th>fire_zip_num_street</th>\n",
       "      <th>sum_fire_prop_loss_street</th>\n",
       "      <th>sum_fire_prop_loss_zip</th>\n",
       "      <th>avg_fire_prop_loss_street</th>\n",
       "      <th>avg_fire_prop_loss_zip</th>\n",
       "      <th>sum_fire_content_loss_street</th>\n",
       "      <th>sum_fire_content_loss_zip</th>\n",
       "      <th>avg_fire_content_loss_street</th>\n",
       "      <th>avg_fire_content_loss_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800 parker</td>\n",
       "      <td>parker 02120</td>\n",
       "      <td>800 parker 02120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663550.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>588.253546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95020.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.237589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39 roxbury</td>\n",
       "      <td>roxbury 02119</td>\n",
       "      <td>39 roxbury 02119</td>\n",
       "      <td>16250.0</td>\n",
       "      <td>3281551.0</td>\n",
       "      <td>345.744681</td>\n",
       "      <td>1116.933628</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>852006.0</td>\n",
       "      <td>37.234043</td>\n",
       "      <td>289.995235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131 walnut</td>\n",
       "      <td>walnut 02119</td>\n",
       "      <td>131 walnut 02119</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>3281551.0</td>\n",
       "      <td>148.648649</td>\n",
       "      <td>1116.933628</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>852006.0</td>\n",
       "      <td>86.486486</td>\n",
       "      <td>289.995235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90 gainsborough</td>\n",
       "      <td>gainsborough 02115</td>\n",
       "      <td>90 gainsborough 02115</td>\n",
       "      <td>10.0</td>\n",
       "      <td>112506.0</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>49.043592</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59162.0</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>25.789887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95 gainsborough</td>\n",
       "      <td>gainsborough 02115</td>\n",
       "      <td>95 gainsborough 02115</td>\n",
       "      <td>10.0</td>\n",
       "      <td>112506.0</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>49.043592</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59162.0</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>25.789887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zipcode  estimated property loss  estimated content loss  fire_num_street  \\\n",
       "0   02120                      0.0                     0.0       800 parker   \n",
       "1   02119                      0.0                     0.0       39 roxbury   \n",
       "2   02119                      0.0                     0.0       131 walnut   \n",
       "3   02115                      0.0                     0.0  90 gainsborough   \n",
       "4   02115                      0.0                     0.0  95 gainsborough   \n",
       "\n",
       "      fire_zip_street    fire_zip_num_street  sum_fire_prop_loss_street  \\\n",
       "0        parker 02120       800 parker 02120                        0.0   \n",
       "1       roxbury 02119       39 roxbury 02119                    16250.0   \n",
       "2        walnut 02119       131 walnut 02119                    16500.0   \n",
       "3  gainsborough 02115  90 gainsborough 02115                       10.0   \n",
       "4  gainsborough 02115  95 gainsborough 02115                       10.0   \n",
       "\n",
       "   sum_fire_prop_loss_zip  avg_fire_prop_loss_street  avg_fire_prop_loss_zip  \\\n",
       "0                663550.0                   0.000000              588.253546   \n",
       "1               3281551.0                 345.744681             1116.933628   \n",
       "2               3281551.0                 148.648649             1116.933628   \n",
       "3                112506.0                   0.243902               49.043592   \n",
       "4                112506.0                   0.243902               49.043592   \n",
       "\n",
       "   sum_fire_content_loss_street  sum_fire_content_loss_zip  \\\n",
       "0                           0.0                    95020.0   \n",
       "1                        1750.0                   852006.0   \n",
       "2                        9600.0                   852006.0   \n",
       "3                          10.0                    59162.0   \n",
       "4                          10.0                    59162.0   \n",
       "\n",
       "   avg_fire_content_loss_street  avg_fire_content_loss_zip  \n",
       "0                      0.000000                  84.237589  \n",
       "1                     37.234043                 289.995235  \n",
       "2                     86.486486                 289.995235  \n",
       "3                      0.243902                  25.789887  \n",
       "4                      0.243902                  25.789887  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fire_df.shape)\n",
    "print(fire_df.isna().sum().sum())\n",
    "fire_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 311 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T21:37:12.116485Z",
     "start_time": "2020-06-05T21:37:12.086164Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68609, 13)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_num</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>reason_category</th>\n",
       "      <th>source_category</th>\n",
       "      <th>req_num_street</th>\n",
       "      <th>req_zip_street</th>\n",
       "      <th>req_zip_num_street</th>\n",
       "      <th>requests_total_prop</th>\n",
       "      <th>requests_total_street</th>\n",
       "      <th>requests_total_zip</th>\n",
       "      <th>req_open_status_prop</th>\n",
       "      <th>req_open_status_street</th>\n",
       "      <th>req_open_status_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6-8</td>\n",
       "      <td>02124</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6-8 school st</td>\n",
       "      <td>6-8 school st 02124</td>\n",
       "      <td>6-8 school st 02124</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>14465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>02130</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>195 south st</td>\n",
       "      <td>195 south st 02130</td>\n",
       "      <td>195 south st 02130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>02122</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>34 ridgewood st</td>\n",
       "      <td>34 ridgewood st 02122</td>\n",
       "      <td>34 ridgewood st 02122</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02124</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3 school st</td>\n",
       "      <td>3 school st 02124</td>\n",
       "      <td>3 school st 02124</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>14465</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>02127</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>22 ward st</td>\n",
       "      <td>22 ward st 02127</td>\n",
       "      <td>22 ward st 02127</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15029</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  st_num zipcode  reason_category  source_category   req_num_street  \\\n",
       "0    6-8   02124               11                0    6-8 school st   \n",
       "1    195   02130                7                2     195 south st   \n",
       "2     34   02122               24                2  34 ridgewood st   \n",
       "3      3   02124               11                0      3 school st   \n",
       "4     22   02127               11                0       22 ward st   \n",
       "\n",
       "          req_zip_street     req_zip_num_street  requests_total_prop  \\\n",
       "0    6-8 school st 02124    6-8 school st 02124                    9   \n",
       "1     195 south st 02130     195 south st 02130                    1   \n",
       "2  34 ridgewood st 02122  34 ridgewood st 02122                    6   \n",
       "3      3 school st 02124      3 school st 02124                   25   \n",
       "4       22 ward st 02127       22 ward st 02127                    5   \n",
       "\n",
       "   requests_total_street  requests_total_zip  req_open_status_prop  \\\n",
       "0                      9               14465                     0   \n",
       "1                      1               11490                     0   \n",
       "2                      6                7438                     0   \n",
       "3                     25               14465                     1   \n",
       "4                      5               15029                     0   \n",
       "\n",
       "   req_open_status_street  req_open_status_zip  \n",
       "0                       0                 1884  \n",
       "1                       0                 1597  \n",
       "2                       0                  885  \n",
       "3                       1                 1884  \n",
       "4                       0                 1845  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(requests_df.shape)\n",
    "print(requests_df.isna().sum().sum())\n",
    "requests_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Combine into One DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:58:45.628645Z",
     "start_time": "2020-06-08T00:58:45.599821Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# RENAME COLUMNS FOR THE MERGE\n",
    "\n",
    "data.rename(columns={\"zipcode\": \"data_zipcode\"}, inplace=True)\n",
    "fire_df.rename(columns={\"zipcode\": \"fire_zipcode\"}, inplace=True)\n",
    "pw_df.rename(columns={\"zipcode\": \"pw_zipcode\"}, inplace=True)\n",
    "requests_df.rename(columns={\"zipcode\": \"requests_zipcode\"}, inplace=True)\n",
    "\n",
    "#=========================================================================================\n",
    "# CHANGE IT ALL BACK\n",
    "\n",
    "# data.rename(columns={\"data_zipcode\": \"zipcode\"}, inplace=True)\n",
    "# fire_df.rename(columns={\"fire_zipcode\": \"zipcode\"}, inplace=True);\n",
    "# pw_df.rename(columns={\"pw_zipcode\": \"zipcode\"}, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T02:38:18.118149Z",
     "start_time": "2020-06-08T02:38:17.741194Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATE A NEW DATAFRAME TO MERGE INTO\n",
    "main = pd.DataFrame()\n",
    "\n",
    "# MERGE DATA WITH PW VIOLATIONS\n",
    "main = pd.merge(data, pw_df, \n",
    "                   how=\"left\", \n",
    "                   left_on=[\"zip_num_street\"],\n",
    "                   right_on=[\"pw_zip_num_street\"])\n",
    "\n",
    "# MERGE MAIN WITH FIRE INCIDENTS\n",
    "main = pd.merge(main, fire_df,\n",
    "                how=\"left\",\n",
    "                left_on=[\"zip_num_street\"],\n",
    "                right_on=[\"fire_zip_num_street\"])\n",
    "\n",
    "# MERGE MAIN WITH 311 REQUESTS\n",
    "main = pd.merge(main, requests_df,\n",
    "                how=\"left\",\n",
    "                left_on=[\"zip_num_street\"],\n",
    "                right_on=[\"req_zip_num_street\"])\n",
    "\n",
    "main[\"label_zip\"] = main[\"data_zipcode\"].astype(\"category\")\n",
    "main[\"label_zip\"] = main[\"label_zip\"].cat.codes + 1 # SHIFTS UP THE LABEL COLUMN UP ONE VALUE\n",
    "main.rename(columns={\"data_zipcode\": \"zipcode\"}, inplace=True);\n",
    "\n",
    "# main[\"label_street\"] = main[\"st_name\"].astype(\"category\")\n",
    "# main[\"label_street\"] = main[\"label_street\"].cat.codes + 1 # SHIFTS UP THE LABEL COLUMN UP ONE VALUE\n",
    "# main.rename(columns={\"data_zipcode\": \"zipcode\"}, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T02:38:21.005801Z",
     "start_time": "2020-06-08T02:38:20.975968Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main.drop(columns=[\n",
    "    \"st_num\",\n",
    "    \"st_name\",\n",
    "    \"num_street\",\n",
    "#     \"zip_street\",\n",
    "#     \"zip_num_street\",\n",
    "#     \"zipcode\",\n",
    "    \"lu_category\",\n",
    "    \"pw_num_street\",\n",
    "    \"pw_zipcode\",\n",
    "    \"pw_zip_street\",\n",
    "    \"pw_zip_num_street\",\n",
    "    \"fire_zipcode\",\n",
    "    \"fire_num_street\",\n",
    "    \"fire_zip_street\",\n",
    "    \"fire_zip_num_street\",\n",
    "    \"requests_zipcode\",\n",
    "    \"req_num_street\",\n",
    "    \"req_zip_street\",\n",
    "    \"req_zip_num_street\"\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T02:38:24.501716Z",
     "start_time": "2020-06-08T02:38:24.464399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# NEED TO REVISIT THIS\n",
    "main.fillna(value=0, inplace=True);\n",
    "\n",
    "# THE IDEA IS THAT, IN THEORY, IF NAN NOT IN MAIN BUT IN OTHER DF\n",
    "# THEN THERE ARE NO METRICS TO HAVE BEEN REPORTED IN THAT DISTRICT/ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T02:38:24.871759Z",
     "start_time": "2020-06-08T02:38:24.818536Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97515, 45)\n",
      "(17629, 59)\n",
      "(21051, 22)\n",
      "\n",
      "Number zipcodes not shared in data and pw_df:\n",
      "79886\n",
      "\n",
      "Number zipcodes not shared in data and fire_df:\n",
      "76464\n",
      "\n",
      "Number zipcodes not shared in data and requests_df:\n",
      "28906\n",
      "\n",
      "Number of null in main:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(pw_df.shape)\n",
    "print(fire_df.shape)\n",
    "print()\n",
    "print(\"Number zipcodes not shared in data and pw_df:\")\n",
    "print(data.shape[0] - pw_df.shape[0])\n",
    "print()\n",
    "print(\"Number zipcodes not shared in data and fire_df:\")\n",
    "print(data.shape[0] - fire_df.shape[0])\n",
    "print()\n",
    "print(\"Number zipcodes not shared in data and requests_df:\")\n",
    "print(data.shape[0] - requests_df.shape[0])\n",
    "print()\n",
    "print(\"Number of null in main:\")\n",
    "print(main.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T02:38:26.589511Z",
     "start_time": "2020-06-08T02:38:26.585533Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[\"label_zip\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T02:38:26.885102Z",
     "start_time": "2020-06-08T02:38:26.872551Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[\"zipcode\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:58:56.651910Z",
     "start_time": "2020-06-08T00:58:52.996304Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/clean-data/data-engineered.csv\")\n",
    "pw_df.to_csv(\"../data/clean-data/pw_df-engineered.csv\")\n",
    "fire_df.to_csv(\"../data/clean-data/fire_df-engineered.csv\")\n",
    "requests_df.to_csv(\"../data/clean-data/requests_df-engineered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T00:06:44.599312Z",
     "start_time": "2020-06-04T00:06:39.452Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_1.to_csv(\"../data/clean-data/data_1-eng.csv\")\n",
    "# pd.read_csv(\"../data/clean-data/data_1-eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T02:38:37.442099Z",
     "start_time": "2020-06-08T02:38:30.216789Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# THE NEW CLEAN, EDA AND MODEL READY DATAFRAME\n",
    "main.to_csv(\"../data/clean-data/main-engineered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
